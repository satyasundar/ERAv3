{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Parameters : 15410\n",
      "Network(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(8, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(12, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(16, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=980, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network, self).__init__()\n",
    "        self.conv1  = nn.Conv2d(1, 8, 3, padding=1)\n",
    "        self.conv2  = nn.Conv2d(8, 12, 3, padding=1)\n",
    "        self.pool1  = nn.MaxPool2d(2,2)\n",
    "        self.conv3  = nn.Conv2d(12, 16, 3, padding=1)\n",
    "        self.conv4  = nn.Conv2d(16, 20, 3, padding=1)\n",
    "        self.pool2  = nn.MaxPool2d(2, 2) \n",
    "\n",
    "        self.fc1    = nn.Linear(20*7*7, 10)\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = x.view(-1, 20*7*7)\n",
    "        x = self.fc1(x)\n",
    "        return x\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Network().to(device)\n",
    "total_parameters = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total Parameters : {total_parameters}\")\n",
    "print(model)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "batch_size = 128\n",
    "\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                    transform=transforms.Compose([\n",
    "                        #  transforms.RandomApply([transforms.CenterCrop(22)], p=0.1),\n",
    "                        #  transforms.Resize((28, 28)),\n",
    "                         #transforms.RandomRotation((-15., 15.)),\n",
    "                         transforms.RandomRotation(15),\n",
    "                        # transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize((0.1307,), (0.3081,))\n",
    "                    ])),\n",
    "    batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape after Conv2: torch.Size([128, 20, 14, 14])\n",
      "(128, 20, 14, 14)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "intermediate_outputs = {}\n",
    "\n",
    "def hook_fn(module, input, output):\n",
    "    intermediate_outputs[module] = output\n",
    "\n",
    "model = Network()\n",
    "hook1 = model.conv1.register_forward_hook(hook_fn)\n",
    "hook2 = model.conv2.register_forward_hook(hook_fn)\n",
    "hook3 = model.pool1.register_forward_hook(hook_fn)\n",
    "hook4 = model.conv3.register_forward_hook(hook_fn)\n",
    "hook5 = model.conv4.register_forward_hook(hook_fn)\n",
    "\n",
    "\n",
    "output = model(images)\n",
    "print(\"Output shape after Conv2:\", intermediate_outputs[model.conv4].shape)\n",
    "#hook1.remove()\n",
    "\n",
    "# Get feature map from conv1\n",
    "feature_map = intermediate_outputs[model.conv4].detach().cpu().numpy()\n",
    "print(feature_map.shape)\n",
    "\n",
    "# Plot the feature maps\n",
    "fig, axes = plt.subplots(1, 8, figsize=(10, 10))\n",
    "\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "    if i < feature_map.shape[1]:  # Number of channels in the feature map\n",
    "        ax.imshow(feature_map[0, i], cmap='gray')  # Show one channel\n",
    "        ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-2114004243709952.0 batch_id=468: 100%|██████████| 469/469 [00:10<00:00, 46.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -2149384595371248.7500, Accuracy: 5739/10000 (57.39%)\n",
      "\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss=-7.93612288744489e+16 batch_id=468: 100%|██████████| 469/469 [00:09<00:00, 47.58it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: -82267222672266384.0000, Accuracy: 5739/10000 (57.39%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    pbar = tqdm(train_loader)\n",
    "    for batch_idx, (data, target) in enumerate(pbar):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        #loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
    "\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "model = Network().to(device)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(0, 2):\n",
    "    print(epoch+1)\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
